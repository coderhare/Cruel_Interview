#### 设计一个LRU缓存

使用自定义的双向链表实现了O(1)的移动队列元素，以及使用哈希表来实现均摊O(1)的查询队列中元素。

```c++
class LRUCache {
    struct Node{
        Node * l, * r;
        int k, v;
        Node(int k_, int v_): k(k_), v(v_), l(nullptr), r(nullptr){}
    };
    int capacity;
    unordered_map <int, Node*> cache;
    Node * head, * tail;
public:
    LRUCache(int capacity) {
        head = new Node(-1, -1);
        tail = new Node(-1, -1);
        this->capacity = capacity;
        head->r = tail;
        tail->l = head;
    }
    void moveToHead(Node * node){
        removeNode(node);
        addToHead(node);
    }
    void addToHead(Node * node){
        node->r = head->r;
        node->l = head;
        head->r->l = node;
        head->r = node;
    }
    void removeNode(Node * node){
        node->l->r = node->r;
        node->r->l = node->l;
    }
    Node * removeTail(){
        Node * node = tail->l;
        removeNode(node);
        return node;
    }
    int get(int key) {
        if(!cache.count(key)) return -1;
        auto node = cache[key];
        moveToHead(node);
        return node->v;
    }

    void put(int key, int value) {
        if(cache.count(key)) {
            auto node = cache[key];
            node->v = value;
            moveToHead(node);
        }
        else{
            auto node = new Node(key, value);
            cache.insert({key, node});
            addToHead(node);
            if(cache.size() > capacity){
                auto removed = removeTail();
                cache.erase(removed->k);
                removeNode(removed);
                delete removed;
            }
        }
    }
};

/**
 * Your LRUCache object will be instantiated and called as such:
 * LRUCache* obj = new LRUCache(capacity);
 * int param_1 = obj->get(key);
 * obj->put(key,value);
 */
```

### 说说什么是死锁，产生的条件，如何解决？

##### 死锁:

是指多个进程在执行过程中，因争夺资源而造成了互相等待。此时系统产生了死锁。比如两只羊过独木桥，若两只羊互不相让，争着过桥，就产生死锁。

##### 产生的条件：死锁发生有四个必要条件：

（1）互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问，只能等待，直到进程使用完成后释放该资源；

（2）请求保持条件：进程获得一定资源后，又对其他资源发出请求，但该资源被其他进程占有，此时请求阻塞，而且该进程不会释放自己已经占有的资源；

（3）不可剥夺条件：进程已获得的资源，只能自己释放，不可剥夺；

（4）环路等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。

##### 如何解决：

（1）资源一次性分配，从而解决请求保持的问题

（2）可剥夺资源：当进程新的资源未得到满足时，释放已有的资源；

（3）资源有序分配：资源按序号递增，进程请求按递增请求，释放则相反。

### 物理内存：物理内存有四个层次，分别是寄存器、高速缓存、主存、磁盘。

- 寄存器：速度最快、量少、价格贵。

- 高速缓存：次之。

- 主存：再次之。

- 磁盘：速度最慢、量多、价格便宜。

操作系统会对物理内存进行管理，有一个部分称为内存管理器(memory manager)，它的主要工作是有效的管理内存，记录哪些内存是正在使用的，在进程需要时分配内存以及在进程完成时回收内存。

虚拟内存：操作系统为每一个进程分配一个独立的地址空间，却是虚拟内存。虚拟内存与物理内存存在映射关系，通过页表寻址完成虚拟地址和物理地址的转换。

为什么要用虚拟内存：因为早期的内存分配方法存在以下问题：

（1）进程地址空间不隔离。会导致数据被随意修改。

（2）内存使用效率低。

（3）程序运行的地址不确定。操作系统随机为进程分配内存空间，所以程序运行的地址是不确定的。

#### 使用虚拟内存的好处：

（1）扩大地址空间。每个进程独占一个4G空间，虽然真实物理内存没那么多。

（2）内存保护：防止不同进程对物理内存的争夺和践踏，可以对特定内存地址提供写保护，防止恶意篡改。

（3）可以实现内存共享，方便进程通信。

（4）可以避免内存碎片，虽然物理内存可能不连续，但映射到虚拟内存上可以连续。

#### 使用虚拟内存的缺点：

（1）虚拟内存需要额外构建数据结构，占用空间。

（2）虚拟地址到物理地址的转换，增加了执行时间。

（3）页面换入换出耗时。

（4）一页如果只有一部分数据，浪费内存。

##### 在请求分页管理中，采用FIFO页面置换算法，可能产生Belady现象

##### 在一台内存只要4KB的ATM机上，对2，000，000笔存款进行排序，最合适的排序方式是：归并排序

##### socket关键字：

1. `SOCKET_STREAM`流套接字应用TCP协议，提供顺序的，可靠的，基于字节流的双向链接

2. `SOCKET_DGRAM`数据报套接字应用UDP协议，无连接，不固定，不可靠

3. `SOCKET_RAW`初始套接字，提供互联网协议和Internal Network Interfaces的权限

### IO多路复用模型：

- 包括select，poll，epoll
